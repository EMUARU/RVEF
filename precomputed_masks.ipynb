{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "########################################################################\n",
    "# 0. 設定裝置\n",
    "########################################################################\n",
    "dev = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device = torch.device(dev)\n",
    "\n",
    "########################################################################\n",
    "# 1. UNet 分割模型定義與載入\n",
    "########################################################################\n",
    "class DoubleConv(nn.Module):\n",
    "    \"\"\"(Conv -> BN -> ReLU) * 2\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, mid_channels=None):\n",
    "        super().__init__()\n",
    "        if not mid_channels:\n",
    "            mid_channels = out_channels\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, mid_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(mid_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(mid_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"下採樣：MaxPool + DoubleConv\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.maxpool_conv(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    \"\"\"上採樣：Upsample/ConvTranspose + DoubleConv with skip connection\"\"\"\n",
    "    def __init__(self, in_channels, out_channels, bilinear=True):\n",
    "        super().__init__()\n",
    "        if bilinear:\n",
    "            self.up = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n",
    "            self.conv = DoubleConv(in_channels, out_channels, in_channels // 2)\n",
    "        else:\n",
    "            self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "            self.conv = DoubleConv(in_channels, out_channels)\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class OutConv(nn.Module):\n",
    "    \"\"\"1x1 卷積\"\"\"\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(OutConv, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "\n",
    "class UNet(nn.Module):\n",
    "    \"\"\"簡易 UNet：單通道輸入、單通道輸出\"\"\"\n",
    "    def __init__(self, n_channels, n_classes, bilinear=False):\n",
    "        super(UNet, self).__init__()\n",
    "        self.inc = DoubleConv(n_channels, 64)\n",
    "        self.down1 = Down(64, 128)\n",
    "        self.down2 = Down(128, 256)\n",
    "        self.down3 = Down(256, 512)\n",
    "        factor = 2 if bilinear else 1\n",
    "        self.down4 = Down(512, 1024 // factor)\n",
    "        self.up1 = Up(1024, 512 // factor, bilinear)\n",
    "        self.up2 = Up(512, 256 // factor, bilinear)\n",
    "        self.up3 = Up(256, 128 // factor, bilinear)\n",
    "        self.up4 = Up(128, 64, bilinear)\n",
    "        self.outc = OutConv(64, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        return self.outc(x)\n",
    "\n",
    "# 載入事先訓練好的 U-Net 權重\n",
    "seg_model = UNet(n_channels=1, n_classes=1).to(device)\n",
    "seg_model_path = \"unet_best_model_LV_HorizontalFlip_112.pth\"\n",
    "if os.path.exists(seg_model_path):\n",
    "    seg_model.load_state_dict(torch.load(seg_model_path, map_location=device))\n",
    "    seg_model.eval()\n",
    "    print(f\"成功載入分割模型權重：{seg_model_path}\")\n",
    "else:\n",
    "    raise FileNotFoundError(\"找不到分割模型權重檔案！\")\n",
    "\n",
    "########################################################################\n",
    "# 2. 後處理：取最大連通區 + 凸包\n",
    "########################################################################\n",
    "def apply_edge_prior(binary_mask):\n",
    "    \"\"\"\n",
    "    1) 取最大連通區\n",
    "    2) 取該區域的凸包\n",
    "    3) 回傳精修後的 mask\n",
    "    \"\"\"\n",
    "    if binary_mask.max() <= 1:\n",
    "        mask_uint8 = (binary_mask * 255).astype(np.uint8)\n",
    "    else:\n",
    "        mask_uint8 = binary_mask.copy()\n",
    "\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask_uint8, connectivity=8)\n",
    "    if num_labels > 1:\n",
    "        largest_label = 1 + np.argmax(stats[1:, cv2.CC_STAT_AREA])  # 找最大區域\n",
    "        largest_component = (labels == largest_label).astype(np.uint8) * 255\n",
    "    else:\n",
    "        largest_component = mask_uint8.copy()\n",
    "\n",
    "    contours, _ = cv2.findContours(largest_component, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return largest_component\n",
    "    largest_contour = max(contours, key=cv2.contourArea)\n",
    "    hull = cv2.convexHull(largest_contour)\n",
    "\n",
    "    refined_mask = np.zeros_like(largest_component)\n",
    "    cv2.drawContours(refined_mask, [hull], -1, 255, thickness=-1)\n",
    "    return refined_mask\n",
    "\n",
    "def get_final_mask(binary_mask):\n",
    "    return apply_edge_prior(binary_mask)\n",
    "\n",
    "########################################################################\n",
    "# 3. 產生遮罩\n",
    "########################################################################\n",
    "def precompute_video_masks(video_path, seg_model, transform, device,\n",
    "                           threshold=0.5, mask_dir=\"precomputed_masks\"):\n",
    "    \"\"\"\n",
    "    讀取影片每一幀, 用 U-Net 產生 soft mask → 二值化 → refined mask\n",
    "    最後存成 .npy，檔名: {video_basename}_masks.npy\n",
    "    \"\"\"\n",
    "    if not os.path.exists(mask_dir):\n",
    "        os.makedirs(mask_dir)\n",
    "\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    if not cap.isOpened():\n",
    "        print(\"無法開啟影片:\", video_path)\n",
    "        return None\n",
    "\n",
    "    video_basename = os.path.splitext(os.path.basename(video_path))[0]\n",
    "    save_path = os.path.join(mask_dir, f\"{video_basename}_masks.npy\")\n",
    "\n",
    "    masks = []\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # 1) 灰階化\n",
    "        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        pil_img = Image.fromarray(gray)\n",
    "\n",
    "        # 2) transform => (1,1,112,112)\n",
    "        inp = transform(pil_img).unsqueeze(0).to(device)\n",
    "\n",
    "        # 3) U-Net 前向推論\n",
    "        with torch.no_grad():\n",
    "            seg_out = seg_model(inp)\n",
    "            soft_mask = torch.sigmoid(seg_out).cpu().numpy().squeeze()\n",
    "\n",
    "        # 4) 二值化 + 後處理\n",
    "        binary_mask = (soft_mask > threshold).astype(np.uint8)\n",
    "        refined_mask = get_final_mask(binary_mask)\n",
    "        masks.append(refined_mask)\n",
    "\n",
    "    cap.release()\n",
    "    masks = np.stack(masks, axis=0)  # (num_frames, H, W)\n",
    "    np.save(save_path, masks)\n",
    "    print(f\"產生遮罩檔: {save_path}\")\n",
    "    return save_path\n",
    "\n",
    "########################################################################\n",
    "# 4. 主程式: 對 CSV 清單中的影片產生遮罩\n",
    "########################################################################\n",
    "if __name__ == \"__main__\":\n",
    "    # CSV檔與影片所在資料夾\n",
    "    csv_file   = \"a4c-video-dir/FileList.csv\"\n",
    "    videos_dir = \"a4c-video-dir/Videos\"\n",
    "    mask_dir   = \"precomputed_masks\"\n",
    "\n",
    "    # 分割模型預處理 (保持與訓練時一致)\n",
    "    seg_transform = transforms.Compose([\n",
    "        transforms.Resize((112, 112)),\n",
    "        transforms.ToTensor()\n",
    "    ])\n",
    "\n",
    "    # 讀取 CSV, 對每支影片做遮罩推論\n",
    "    df_all = pd.read_csv(csv_file)\n",
    "    for idx, row in df_all.iterrows():\n",
    "        fn = row[\"FileName\"]\n",
    "        if not fn.lower().endswith(\".avi\"):\n",
    "            fn += \".avi\"\n",
    "        video_path = os.path.join(videos_dir, fn)\n",
    "\n",
    "        base_name = os.path.splitext(os.path.basename(fn))[0]\n",
    "        save_path = os.path.join(mask_dir, f\"{base_name}_masks.npy\")\n",
    "\n",
    "        # 若檔案尚未產生, 則進行推論\n",
    "        if not os.path.exists(save_path):\n",
    "            print(f\"[precompute] 處理 {fn} ...\")\n",
    "            precompute_video_masks(\n",
    "                video_path, seg_model, seg_transform,\n",
    "                device=device, threshold=0.5, mask_dir=mask_dir\n",
    "            )\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "m123140014",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
